---
title:  "2.4 Error Backpropagation"
excerpt: 

categories:
  - Robot
tags:
  - [Deep Learning]

toc: true
toc_sticky: true
 
date: 2022-10-23
last_modified_at: 2022-10-23

use_math: true
published: true
---

<br>

Deep learning은 <span style="color:red">**feedforward**</span>와 <span style="color:red">**backpropagation**</span>이라는 두 단계로 진행된다.

<br>

<p align="center"><img src="/assets/image/machine_learning/dl/ch2/221023_1.svg" width="" height="" title="" alt=""><br/></p>

<br>

Feedforward는 네트워크에 training data가 들어올 떄 발생한다. Prediction 계산을 위해 전체 neural network를 교차해 지나간다. 모든 neuron이 계산을 완료하면 예측값이 output layer에 도달하게 된다.

그 다음은 loss function으로 예측값과 실제 값의 오차를 추정한다. Loss function의 cost가 0에 가까워지도록 model은 training을 반복하여 weight를 조정해야 한다. 오차 정보는 역방향으로 전파되기 때문에 backpropagation이라고 부른다. 

<br>

***

### 2.4.1 Backpropagation Algorithm

오차가 weight에 기여하려면 어떻게 해야 할까? 수학적으로 생각하면 error를 neuron의 wegiht로 미분한 후 기존의 weight에서 빼면 되겠다. 지금 다시 [Machine Learning 1.1 Linear Regression](https://younghwanjoo1608.github.io/robot/ml1.1/)를 복습하자.

이 과정을 모든 neuron에 대해 진행하면 모든 weight가 업데이트될 것이고, 이 결과를 다시 feedforward 과정에 이용할 수 있을 것이다.

<br>

pytorch의 `autograd`는 gradient를 계산해 준다. `requires_grad=True`를 갖는 두 텐서 `a`, `b`를 만들자. 이는 `autograd`가 모든 연산을 추적할 수 있도록 해준다.

<script src="https://gist.github.com/younghwanJoo1608/fec9791fcad75a573dbc7a62c6522e9b.js"></script>


`a`와 `b`로부터 새로운 텐서 `Q`를 만들자.

$$
Q = 3a^3 - b^2
$$

만약 `a`, `b`가 모두 NN의 parameter이고 `Q`가 오차라면, 우리는 parameter에 대한 error의 gradient를 구해야 하므로.

$$
\frac{\partial Q}{\partial a} = 9a^2 \\
\frac{\partial Q}{\partial b} = -2b
$$

Backpropagation을 진행하기 위해 error tensor에 `.backward()`를 호출한다. 이때 `Q`에 `gradient` 인자를 명시적으로 전달해야 한다. `gradient`는 `Q`와 같은 모양의 텐서로, 자기 자신에 대한 변화도를 의미한다.

$$
\frac{\partial Q}{\partial Q} = 1
$$

<script src="https://gist.github.com/younghwanJoo1608/70570cc36a66c2215297a48c0e7969eb.js"></script>

이제 각 gradient는 `a.grad`, `b.grad`에 전달된다. 한 번 정확한지 확인해보자.

<script src="https://gist.github.com/younghwanJoo1608/5cdf102794ee62ea837bbb7665debff5.js"></script>

```cpp
 - Result : 
tensor([True, True])
tensor([True, True])
```