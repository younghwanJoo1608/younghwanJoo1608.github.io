---
title:  "2.A Extra : Softmax Function Oveflow"
excerpt: 

categories:
  - Robot
tags:
  - [Machine Learning]

toc: true
toc_sticky: true
 
date: 2022-09-06
last_modified_at: 2022-09-06

use_math: true
published: true
---

<br>

Classification에 쓰이는 <span style="color:red">**softmax function**</span>을 다시 한 번 보자.

$$
y_k = \frac{\exp{(a_k)}}{\sum_i \exp{(a_i)}}
$$

Softmax function의 구현에는 한 가지 주의할 점이 있는데, 바로 overflow 문제. 지수함수를 사용하게 떄문에 매우 큰 값이 계산 도중에 필요하게 될 수 있다. 다음과 같이 개선해 보자.

$$\begin{align*}
y_k = \frac{\exp{(a_k)}}{\sum_i \exp{(a_i)}} &= \frac{C\exp{(a_k)}}{C \sum_i \exp{(a_i)}} \\
&= \frac{\exp{(a_k + \log{C})}}{\sum_i \exp{(a_i + \log{C})}} \\
&= \frac{\exp{(a_k + C')}}{\sum_i \exp{(a_i + C')}}
\end{align*}$$

임의의 정수 $C$를 분자와 분모 양쪽에 곱하고, 마지막 등호에서는 $\log{C} = C'$로 대체한 것이다.

여기서 알 수 있는 것은, softmax의 $\exp$ 함수를 계산할 때 어떤 정수를 더하든 빼든 결과는 같다는 것이다. 만약 $C'$에 적절한 값(보통은 input signal 중 최댓값)을 집어넣으면 overflow를 막을 수 있다.

<script src="https://gist.github.com/younghwanJoo1608/16a8ad4c0aa0c47d26063d2f4c7bb254.js"></script>

<br>

이 아이디어를 바탕으로 개선한 softmax function은 다음과 같다.

<script src="https://gist.github.com/younghwanJoo1608/9f5ab27a2108b8329e9f2af3c5d26ae4.js"></script>